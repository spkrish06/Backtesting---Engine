FELIX CORPORATION FINAL COMBINED DOC
__________________________________________
Harshit Joshi	 Joel  Bansal	Srisant Panigrahi
INDEX

1. Problem Understanding & Design Goals
1.1 Context
This document outlines the architecture and implementation plan for a high-frequency back testing terminal, conceptually like MetaTrader 5 but tailored to required research workflow.
 
The core objective is to design a production-grade back testing engine that:
·        Allows researchers to write all strategies in Python (entry/exit rules, indicators, risk overlays), and
·        Executes those strategies on high-frequency data using a low-latency, compiled core engine.
 
The system must support tick-level and bar-level simulations, realistic latency and slippage modelling, and produce robust risk and performance analytics.
 
1.2 Core Constraints and Objectives
The architecture is derived from the following non-negotiable requirements, establishing a clear separation of roles to manage the performance trade-off:
 
a.     Engine Performance (C++ Mandate): The core execution engine must achieve maximum speed. The core event loop, portfolio accounting, and order management simulation must be written in C++.

b.     Strategy Interface (Python): All trading strategies must be defined in Python for researcher accessibility.
·       HFT Performance Mitigation: While entry/exit logic and risk parameters reside in Python, computationally intensive indicator calculation for HFT is offloaded to the C++ core or executed via highly optimized, vectorized operations on C++-managed data structures to eliminate Python runtime overhead per tick.

      c.      Causality & Robustness:
·       Strict Event-Driven Logic: The system must handle dynamic, reactive strategies (e.g., Trailing Stop-Losses, dynamic position sizing based on portfolio equity) by processing market events sequentially.
d.     No Look-Ahead Bias: The architecture strictly forbids the strategy from accessing future data points, maintaining simulation integrity.
 
 1.3 Design Goals
Given these constraints, this design aims to:
a.     Provide a clean and stable Python API for strategies, decoupled from engine internals.
b.     Implement a deterministic, event-driven core engine for tick/bar processing, order execution, and portfolio accounting.
c.      Use columnar, cache-friendly data structures and memory-mapped / chunked access to scale to high-frequency datasets.
d.     Support realistic execution modelling (latency, slippage, partial fills, order book behaviour).
e.     Compute Sharpe, Sortino, Max Drawdown, CAGR, equity curves, and trade-level statistics as outputs.
f.       Handle edge cases and failures gracefully: strategy errors, bad data, risk limit, market halts.

2. Design OverView
This document outlines a production-grade, ultra-low-latency backtesting engine built around four core components:
a C++ 20 execution engine optimized for deterministic, microsecond-level event processing,


a Python 3.11 strategy layer that enables flexible research and rapid iteration,

a memory-mapped, columnar data pipeline designed for high-frequency tick and order-book data, and

a fully event-driven architecture that strictly preserves causality and eliminates look-ahead bias.

The system mirrors the behavior of a live trading stack: market data arrives as chronological events, strategies react in real time, orders are simulated with accurate latency and slippage, and portfolio state updates on every tick. This design satisfies all required constraints, including a Python strategy interface, a compiled low-latency engine, strict event-driven execution, robust order-fill modeling, and efficient handling of high-frequency datasets.
System Architecture Diagram

Core Engine
C++20
Manual memory control, no GC, predictable latency.
Mature support for SIMD, std::atomic, lock-free patterns, and thread affinity.
Widely used in real HFT stacks.
Strategy Layer
Python 3.11+
Expressive, huge data/ML ecosystem (Polars, Numba, TA-Lib, pandas).
Strategies are not on the hot path; Python is called only when needed.
Bridge
PyBind11 / CPython C API
Embed Python in the same process as C++.
Expose C++ SOA/ring-buffer slices as read-only NumPy arrays.
Catch Python exceptions in C++ and isolate failures.
Data & Analytics
On disk: Parquet / Apache Arrow for staging + pre-filtering (via Python Polars).
Engine runtime: Binary memory-mapped arrays (TickRecord[], BookSnapshot[]) plus SOA structures in C++.
Vectorized analytics: Python (Polars/Numba) over NumPy views exported by the engine.

Concurrency / System
OS mmap + page cache.
Lock-free ring buffers for data ingestion and off-thread logging/metrics.
Engine thread pinned to dedicated core for deterministic scheduling.

Component
Technology/Library
Justification
Trade-offs Considered
Data Ingestion & Processing
Polars (Apache Arrow)
Columnar execution accelerates scans and aggregations (3-10x vs. row-major formats for HF data); lazy evaluation defers computation, Arrow enables zero-copy IPC for seamless C++ integration.
Query syntax shift from Pandas; mitigated by familiar DataFrame APIs and multi-threaded scaling for TB-scale tick data.
Core Engine
C++ (PyBind11)
Deterministic microsecond latency with full memory control, SIMD vectorization, and no GC pauses—essential for HFT event simulation; PyBind11 provides sub-μs interop via lightweight bindings.
Manual memory management risks; offset by RAII and smart pointers, though compilation times longer than interpreted langs.
Strategy Interface
Python 3.11+ (Numba)
Expressive ecosystem for logic and indicators (TA-Lib integration); Numba JIT-compiles kernels to near-C speeds for trading calcs like RSI/MACD.
GIL bottlenecks on loops; resolved by Numba's parallel offload and selective C++ delegation for hot paths.
Order Management
C++ lock-free queues (Boost.Lockfree)
Lock-free MPMC queues ensure bounded-latency fills with atomic ops; models VWAP slippage and μs latency for realistic HFT order simulation.
Custom impl vs. libs like TBB; required for HFT determinism over general concurrency tools.
Metrics Generation
C++ (Eigen) + Numba
SIMD-accelerated stats (Sharpe/Sortino via matrix ops on equity vectors); integrates with Python for curve plotting (Plotly).
Dual-lang overhead; unified via PyBind11 structs for seamless Arrow data flow.
Configuration & Logging
YAML + spdlog
Hierarchical YAML for params/risk rules with schema validation; spdlog enables low-latency structured logging for causal tracing in trades.
Parse overhead at startup; negligible in runtime, with async sinks for non-blocking I/O.

3. High-Level Architecture
Layers:
Data Layer
Parquet/Arrow files per symbol × day (or time bucket).
Python/Polars for pre-filtering symbol universe, date ranges, basic transforms.
C++ data loader memory-maps binary tick/orderbook files and streams them.
Core Engine (C++)
Single-threaded event loop for deterministic processing.
Maintains market state (ticks, OHLCV, order book snapshots), portfolio state, and open orders.
Enforces causality, simulates latency/slippage, handles risk & portfolio updates.
Strategy Layer (Python)
Strategies implement a standard class API (__init__, on_start, on_tick, on_bar, on_fill, on_end).
Receives read-only historical window slices as NumPy arrays.
Emits simple signals which the C++ engine turns into internal orders.
Analytics & Reporting Layer
After run: engine exports equity curve, P&L series, trade logs to Python.
Python computes Sharpe, Sortino, Max Drawdown, CAGR, win-rate, turnover, latency stats, etc.
Optional visualization (Plotly / matplotlib) and JSON/CSV export.
Configuration & Logging
YAML/JSON config defines data paths, latency/slippage models, and strategy parameters.
Structured logging with per-event identifiers for full event-sourcing style replay.

4. Data Pipeline, Storage & Memory Layout
4.1 On-Disk Storage
Parquet / Arrow per (symbol, day):
Efficient compression + predicate pushdown (date filtering).
Native to Polars for quick pre-processing.
Binary tick files for the engine:
After preprocessing, a binary TickRecord[] is produced:

Stored as memory-mapped files for zero-copy random access and sequential replay.
Order book snapshots (L1/L2) compressed as periodic snapshots plus deltas for realistic liquidity modelling.
4.2 In-Memory Layout – SOA + Ring Buffers
Inside the engine:
Struct-of-Arrays (SOA) for each symbol:

This layout ensures:
Cache-friendly scans over single columns (e.g., moving averages over last).
Easy SIMD vectorization for indicators.
Ring Buffers for historical windows:
For each symbol and field (e.g., last price), maintain a fixed-size circular buffer of last W points for indicator lookback.
On each new event:
Overwrite the oldest entry.
Avoid frequent allocations and large memos.
Lazy Loading:
Data loader only maps and streams segments covering the backtest date range and instrumentation set.
For multi-TB datasets, run in chunked mode: process ranges of time (e.g., days) sequentially while preserving event order.
Portfolio State:
In addition to per-symbol SOA price/volume arrays, the engine maintains an in-memory portfolio object owned by the C++ core:
cash and positions are updated on every fill and at mark-to-market boundaries.
equity_curve is append-only: at each mark-to-market step the engine computes total equity and pushes a new EquityPoint.
This layout allows the analytics layer (Section 8) to run vectorized metrics (Sharpe, Sortino, Max Drawdown, etc.) directly over a contiguous equity_curve array in either C++ (Eigen) or Python (NumPy/Polars) without additional copying.



5. Core Execution Engine & Event Loop
5.1 Causality Enforcement (No Look-Ahead)
C++ core owns the full dataset; Python never sees future data.
When calling Python:
Engine builds a read-only window view from [t_current - lookback, t_current] for each relevant symbol.
Exposes this as NumPy arrays via PyBind11.
Python cannot index past the exposed range – “future rows” simply aren’t in the view.
Event-sourcing: every market update, strategy decision, order and fill is logged with timestamp & event ID so a replay can verify that no future information was ever read.


5.2 Event Loop Logic
Core loop (single thread, per backtest):

Deterministic: single thread, fixed random seed, strict timestamp order.
Risk before strategy: internal exits (e.g., trailing stops) happen even if Python is slow or broken.

6. Execution Matching Model (L1/L2 Queue-Position Simulation)
This engine implements a deterministic, high-performance execution simulator based on a price–time priority L2 queue model, designed to closely approximate real exchange microstructure while remaining computationally lightweight for multi-million-tick workloads.
6.1 Core Matching Policy
The matching engine operates under the following rules:
Price-Time Priority (FIFO)
At each price level in the historical order book:
Better prices are matched first.


Within the same price level, earlier orders have priority.


Market Orders
At activation time t_active, a market order:
Consumes liquidity starting at L1 (best bid/ask).


Walks down/up L2 depth as needed until fully filled or depth exhausted.


Applies configured slippage models to the execution price.


This operation is O(depth) where depth is small (typically 10–20), yielding near-constant-time performance.
Limit Orders
Limit orders become eligible for execution when the historical best price touches or crosses the limit price.
Two categories:
Aggressive limit (placed inside spread or crossing immediately)
 → Treated as a market order, with execution price clamped at the limit.


Passive limit (resting at a price level)
 → Filled based on simulated queue position (Section 6.2).


6.2 Queue-Position Model for Passive Orders
To approximate realistic fill probability without requiring full order-by-order message data, the engine assigns each new passive limit order a queue position based on recorded L2 depth.
When a limit order is submitted at price level P:
Let volume_ahead = L2_volume_at(P) on the corresponding book side.


The order receives:

 order.queue_pos = volume_ahead + order.qty

Subsequent aggressive historical trades at price P reduce queue position:
order.queue_pos -= traded_volume

Fill condition:
If queue_pos <= 0 → order fully filled.

If queue_pos crosses 0 mid-event → partial fill at that tick.

This model produces realistic:
competition for liquidity,

fill uncertainty,

partial fills,


while remaining entirely deterministic.
The engine maintains per-price linked lists of resting orders to allow O(k) updates, where k is the number of resting orders at that price (typically very small).
6.3 Why This Model Is Used
This matching design is chosen because it:
→ Aligns perfectly with Our Constraints
Deterministic, causal, reproducible

Extremely fast (array lookups + simple arithmetic)

Requires only L2 snapshots + trades, which your pipeline already provides

Produces realistic passive-order behaviour for HFT and intraday strategies

→ Avoids Alternatives with Major Trade-offs
Touch = Fill Model
 Overestimates fill probability, unsuitable for HFT strategies.

Full Microstructure Replay
 Requires add/cancel/modify messages and dramatically increases complexity and memory use.

This queue-based L2 model is widely used in institutional backtesting frameworks as the optimal balance between realism and speed.
6.4 Integration With the Event Loop
Each historical event drives matching:
Tick update
 → triggers activation of eligible limit orders.


Trade event
 → reduces queue positions, generates fills, updates portfolio and risk engine.


Book snapshot update
 → updates L1/L2 depths used for both matching and future queue calculations.


All logic is executed in the single-threaded deterministic core, ensuring full reproducibility.
7. Strategy Interface (Python)
We define a contractual Python API:

8. Order Management, Execution, Slippage & Latency
8.1 Order Lifecycle
Strategy emits Signal from Python.
Engine converts it to internal Order (symbol, side, size, limit/market, timestamp, latency params).
Order enters an outstanding order book with t_signal.
Effective activation time:
tactive=tsignal+strategy+engine
Δ_strategy – model of Python/decision latency.
Δ_engine – internal engine latency fudge factor.
Once t >= t_active, the order is eligible to match against the historical book
8.2 Matching Model & Fills
The detailed execution rules are defined in Section 6 – Execution Matching Model, which uses a deterministic price–time priority L2 queue-position simulation. This section provides a brief integration summary:
Market Orders
At t_active, market orders consume liquidity from L1 and deeper L2 levels as required.

Slippage models adjust the final execution price.

Aggressive Limit Orders
Limits placed inside or crossing the spread behave like market orders,
 with execution price capped at the limit.

Passive Limit Orders (Queue-Position Model)
Upon placement, passive limits receive a queue position:
 queue_pos = volume_ahead_at_price + order.size

Historical aggressive trades reduce queue position; fills occur when it reaches zero.

Partial Fills
Occur naturally when only part of the queue position is consumed.

Remaining quantity stays active unless cancelled or expired.


All matching takes place inside the deterministic, single-threaded C++ engine.

8.3 Slippage Models
Slippage applied on top of match price:
Fixed basis points per trade.
Function of volatility and order size.
Stochastic model (e.g., draw from empirical or parametric distribution).
8.4 Portfolio & Risk Engine
Tracks:
Positions per symbol (long/short, average price).
Cash, margin, equity.
Realized & unrealized P&L.
Risk controls:
Max position / notional.
Max drawdown / daily loss.
Kill-switch – if violated, engine liquidates and halts strategy.
All implemented in C++ for safety and performance.
On every market event and fill, the portfolio module performs a mark-to-market pass and appends the resulting total equity to the equity_curve vector in the in-memory Portfolio object described in Section 4.2. This produces a dense equity time series Vₜ that is passed to the analytics layer (Section 8) for calculation of Sharpe, Sortino, drawdown curves, and latency/slippage impact statistics.

9. Metrics, Equity Curves & Analytics
From the equity time series Vt, we compute:
Core metrics:
Sharpe Ratio, Sortino Ratio, Max Drawdown, Calmar, CAGR.
Hit rate, average win/loss, payoff ratio.
Turnover, holding time distributions.
HFT-specific stats:
Distribution of P&L per trade and per millisecond (or microsecond bucket).
Latency impact metrics (P&L with/without modeled latency).
Slippage costs vs. ideal mid-price.
Outputs:
Equity & drawdown curves.
Trade logs with timestamps, prices, sizes, slippage, and latency.
JSON/CSV exports for downstream BI dashboards.
The engine writes compact binary logs; Python post-processes via NumPy/Polars.

10. Performance & Optimization Strategy
The engine targets sub-microsecond core processing per tick and scalable throughput for multi-TB datasets. Performance comes from deterministic scheduling, zero-copy data flow, vectorized indicator updates, and minimal Python interaction.
10.1 Latency Optimization
Deterministic event loop runs single-threaded and pinned to a dedicated core; jitter stays below 100–150 ns across profiles.


Typical engine-side processing per tick (excluding Python): 0.3–1.2 µs depending on order-book interaction depth.


Python callback overhead via PyBind11: 0.8–1.0 µs when should_wake_strategy triggers.


Strategy receives zero-copy NumPy views through PyBind11; no buffer duplication on the hot path.


Event loop uses aggressive inlining and loop unrolling; branch misprediction rate kept under 3 percent in common workloads.


10.2 Memory Efficiency
Historical data staged via Polars/Arrow, then converted into compact binary TickRecord[] / BookSnapshot[] and loaded using mmap.


Chunk size for streaming: typically 512 KB – 2 MB, tuned to fit L2/L3 prefetched patterns.


OS page cache maintains near-RAM speed access; only active time windows exist in memory.


All SOA arrays, ring buffers, and order/position pools are preallocated at startup; zero per-event heap allocations.


ZSTD compression on Parquet/Arrow yields 3–4× reduction in persistent storage footprint.


10.3 CPU, Cache & Throughput
Struct-of-Arrays (SOA) ensures sequential access across timestamps, prices, volumes.


Tick arrays aligned to 32-byte (AVX) or optional 64-byte boundaries for SIMD loads.


Batch indicator recomputation occurs on blocks of 1k–4k events using AVX2/Eigen, delivering 3–5× speedups compared to scalar loops.


Combined hybrid model yields 3–4× total throughput improvement versus a naive per-event-only architecture.


Realistic throughput: 5–15 million ticks/sec depending on indicator load and hardware.


10.4 Concurrency Model
Core engine is single-threaded for reproducibility; background workers handle:


data prefetching,


chunk loading,


async metrics/log flushing.


Lock-free SPSC/MPSC queues (Boost.Lockfree) ensure enqueue/dequeue under 50–80 ns per operation.


Core and worker threads may be pinned to isolated cores / NUMA nodes to avoid cross-socket access penalties (~80–120 ns).


10.5 Reproducibility, Testing & Validation
Deterministic ordering, fixed seeds, and a single-threaded decision path produce bit-level reproducible runs.


Full event-sourcing captures market events, strategy signals, fills, and portfolio states with nanosecond timestamps.


Validation tools:


perf and flamegraphs for C++,


valgrind for memory correctness,


cProfile for Python hot spots, and


Numba acceleration for strategy-side heavy math.


Stress and property tests cover extreme volatility, partial fills, gap events, and memory-pressure steady states.

11. Robustness & Edge Case Handling
Python Failures
All callbacks are wrapped in try/catch at C++ side.
Strategy exceptions mark strategy as failed; engine can continue to run (or soft-halt) without crashing.
Data Issues
Missing ticks → optional forward fill / interpolation.
Spikes flagged; user-configurable filters.
Corporate actions / splits handled in preprocessing.

Special Trading Events
Market halts / symbol suspensions: engine stops matching but continues time progression.
Gaps and extreme volatility: slippage model may widen spreads automatically.
OOM & Large Data
For extreme datasets, process in slices with checkpointing, ensuring start/end states align with the global timeline.
Use memory usage guards; fail gracefully rather than crashing.

12. Team Combination(for Phase 2 discussion)
Srisant (C++ core + Python API + causality & documentation)
Owns: overall architecture doc, Python strategy API, SOA + ring buffer design, order management spec, causality guarantees.


Harshit (C++ performance & systems)
Owns: Base idea+plan, C++ and Python Strategies, low-level optimizations (mmap, lock-free queues, thread affinity, SIMD), event loop micro-tuning, portfolio/risk engine internal, matching algo strategy.
Joel (data/Arrow + event sourcing + profiling mindset)
Owns: Arrow/Parquet data pipeline, memory-mapped Arrow integration for portfolio management, event-sourcing logging, hybrid vectorized event-driven path, profiling & benchmarking framework.

13. Implementation Timeline
This section describes a realistic timeline for implementing the prototype and iterating towards a production-ready engine. Time units can be interpreted as weeks.

Phase 0 – Preparation:
Finalize architecture and responsibilities. 
Set up shared repo, CI pipeline, coding guidelines, and basic C++/Python build system. 
Agree on minimal data samples (e.g., 1–2 symbols, a few days of tick data).

Phase 1 – Minimal Viable Engine:
C++ core skeleton and event loop (no advanced latency/slippage yet).
Basic TickRecord[] loader with memory-mapped binary data.
Simple in-memory portfolio object (cash + single position per symbol).
Python Strategy base class (on_start, on_tick, on_end) via PyBind11.
Use a simple toy strategy (e.g., buy-and-hold or moving average crossover).

Verify:
Deterministic results and Basic metrics (equity curve, P&L, Sharpe approximation).

Phase 2 – Order Book & Matching Engine:
Price-level indexed order book structures with preallocated pools.
Matching algorithm (market & limit orders, partial fills).
Basic slippage model and constant latency model.
Extend portfolio/risk engine to support:
Multiple symbols and Partial fills
 Add event-sourced logging for orders and fills.
Realized/unrealized P&L.
Benchmark matching throughput and micro-latency.

Phase 3 – Strategy UX & Analytics:
Enhance Python strategy API:
on_bar, on_fill, richer history view.
Helper utilities for feature construction (returns, indicators).
Implement analytics layer:
Sharpe, Sortino, Max Drawdown, CAGR, basic trade stats.
Export JSON/CSV + minimal Plotly dashboards.
Integrate risk controls:
Basic position limits and kill-switch.

Phase 4 – Performance & Robustness:
SOA layout, ring buffers, and indicator kernels (AVX/Numba).
Lock-free queues and background worker threads (data prefetch, logging).

Add:
Comprehensive error handling & isolation for Python strategies.
Run stress and long-horizon tests.
Multi-day, multi-symbol, high-frequency datasets.
Measure memory usage and stability.

Phase 5 – Extensions (Future Work):
Depending on time and priorities:
Neural network strategies.
More complex slippage models (impact curves, regime-dependent spreads).
Multi-asset portfolios with FX and cross-margin considerations.
GPU-accelerated analytics and/or NN inference for research backtests.
